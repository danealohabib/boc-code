{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Set-Up\" data-toc-modified-id=\"Set-Up-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Set Up</a></span></li><li><span><a href=\"#QE4b\" data-toc-modified-id=\"QE4b-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>QE4b</a></span><ul class=\"toc-item\"><li><span><a href=\"#General-Cleaning\" data-toc-modified-id=\"General-Cleaning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>General Cleaning</a></span></li><li><span><a href=\"#N-Grams\" data-toc-modified-id=\"N-Grams-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>N-Grams</a></span></li><li><span><a href=\"#Key-Word-Analysis\" data-toc-modified-id=\"Key-Word-Analysis-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Key Word Analysis</a></span></li><li><span><a href=\"#Combinations?\" data-toc-modified-id=\"Combinations?-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Combinations?</a></span></li><li><span><a href=\"#Try-Delimiting?---Online\" data-toc-modified-id=\"Try-Delimiting?---Online-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Try Delimiting? - Online</a></span></li><li><span><a href=\"#Try-Delimiting?---Card\" data-toc-modified-id=\"Try-Delimiting?---Card-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Try Delimiting? - Card</a></span></li><li><span><a href=\"#Try-Delimiting?---Business\" data-toc-modified-id=\"Try-Delimiting?---Business-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Try Delimiting? - Business</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an analysis of two questions from the 2020 Cash Alternative Survey (Wave 2): \n",
    "\n",
    "**E4b** Please tell us the reasons why you have changed the way you pay. What concerns, if any, do you have?\n",
    "\n",
    "**E3** Asks for general comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:47:14.351517Z",
     "start_time": "2021-03-16T15:47:07.088653Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from spellchecker import SpellChecker\n",
    "from langdetect import detect\n",
    "# non-deterministic algorithm; different results for short / ambiguous text\n",
    "# the code below ensures consistent results \n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "import math\n",
    "\n",
    "# NLTK library\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# General\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display # display allows for >1 output per cell\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Mute error warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:50:57.087596Z",
     "start_time": "2021-03-16T15:50:51.795873Z"
    }
   },
   "outputs": [],
   "source": [
    "input_files_path = \"C:\\\\MOP_Survey\\\\trunk\\\\Methods-of-Payment surveys\\\\2020\\\\CAS Wave 2\\\\Data\\\\Final data files\\\\20-054726-01-09-Diary_FNL.dta\"\n",
    "mop_2020 = pd.read_stata(input_files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:58:10.587105Z",
     "start_time": "2021-03-16T15:58:10.582130Z"
    }
   },
   "outputs": [],
   "source": [
    "# The list of stopwords that will be removed\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(stopwords.words('french'))\n",
    "\n",
    "# Exclude the following words (as they can alter the context of a response)\n",
    "include = [\"don't\",\"won't\"]\n",
    "stop_words = [x for x in stop_words if x not in include]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:40:24.457243Z",
     "start_time": "2021-03-16T19:40:24.446272Z"
    },
    "code_folding": [
     0,
     8,
     18,
     34,
     38,
     53,
     70,
     86,
     104,
     113
    ]
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(df, col_name, stop_words):\n",
    "    \"\"\"\n",
    "    Removes all words in stop_words from df['col_name']\n",
    "    \"\"\"\n",
    "    df[col_name] = df[col_name].apply(\n",
    "        lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    \"\"\"\n",
    "    Adapted from: https://stackoverflow.com/questions/39782418/remove-punctuations-in-pandas/39782973\n",
    "    \"\"\"\n",
    "    for punctuation in string.punctuation:\n",
    "        if punctuation != \"'\":\n",
    "            text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "\n",
    "def response_to_word(col_list):\n",
    "    \"\"\"\n",
    "    Given a col_list E.X. [\"covid\", \"i have gone out less\",...], returns a list of words i.e [\"covide\", \"i\",...]\n",
    "    \"\"\"\n",
    "\n",
    "    # list to store all words\n",
    "    complete_word_list = []\n",
    "    # Iterate through response\n",
    "    for response in col_list:\n",
    "        # Convert the response to a list of words\n",
    "        word_list = re.findall(r\"([\\w][\\w']*\\w)\", response)\n",
    "        # Extend question_E4b_en_word_list with this list of words\n",
    "        complete_word_list.extend(word_list)\n",
    "    return complete_word_list\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "\n",
    "def get_ngrams_discern(sentence_list, n):\n",
    "    \"\"\"\n",
    "    Returns a Counter containing all ngrams in sentence_list and frequencies.\n",
    "    Ensures there is no overlap between respondents\n",
    "\n",
    "    Parameters:\n",
    "        sentence_list (list): a list of list of responses ~ [[\"response 1\"], []\"response 2\"],...]\n",
    "        n (int): the number of adjacent words to look for\n",
    "    Returns:\n",
    "        ngram_counter (Counter): containing all ngrams in sentence_list and frequencies.\n",
    "    \"\"\"\n",
    "    # List to store all ngrams\n",
    "    n_grams_list = []\n",
    "\n",
    "    # Iterate through each sentence\n",
    "    for i in range(len(sentence_list)):\n",
    "\n",
    "        # Create the ngram for the current sentence\n",
    "        n_grams = ngrams(sentence_list[i].split(), n)\n",
    "\n",
    "        # Create a Counter to count the number of times each ngram occurs in n_grams\n",
    "        n_grams_frequencies = Counter(n_grams)\n",
    "\n",
    "        # Iterate through all the ngrams of the response\n",
    "        for ngram in n_grams_frequencies:\n",
    "\n",
    "            n_grams_list.append(ngram)\n",
    "\n",
    "    # Create Counter where key:value pairs represent word:frequency\n",
    "    return Counter(n_grams_list)\n",
    "\n",
    "\n",
    "def tabulate_counter(counter, n):\n",
    "    \"\"\"\n",
    "    Prints the top n occurring in counter\n",
    "    \"\"\"\n",
    "    most_common = counter.most_common(n)\n",
    "    most_common_table = []\n",
    "\n",
    "    for i in most_common:\n",
    "        row = []\n",
    "        row.append(i[0])\n",
    "        row.append(i[1])\n",
    "        most_common_table.append(row)\n",
    "\n",
    "    print(tabulate(most_common_table))\n",
    "\n",
    "\n",
    "def print_query_results(search_terms, col_name, df, num):\n",
    "    \"\"\"\n",
    "    Prints num rows in df[col_name] that contains >1 word from search_terms\n",
    "\n",
    "    search_terms: a list of search words\n",
    "    col_name: the column name that is searched\n",
    "    df: the dataframe that is searched\n",
    "    \"\"\"\n",
    "    query = df[df[col_name].str.contains(\n",
    "        '|'.join(search_terms))]\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in query.iterrows():\n",
    "        print(f\"{row[col_name]}\\n\")\n",
    "        counter += 1\n",
    "        if counter == num:\n",
    "            break\n",
    "\n",
    "def query_num(search_terms, col_name, df):\n",
    "    \"\"\"\n",
    "    Counts the number of times search_terms appears in df[col]\n",
    "    \"\"\"\n",
    "    query = df[df[col_name].str.contains(\n",
    "        '|'.join(search_terms))]\n",
    "\n",
    "    return query.shape[0]\n",
    "\n",
    "def categorize(search_terms, search_col, category_col, df):\n",
    "    \"\"\"\n",
    "    Sets value in category_col to 1 if search_col contains > 1 search_terms\n",
    "\n",
    "    search_terms: list of search terms\n",
    "    serach_col: string name of column that is searched\n",
    "    category_col: string name of column that is updated\n",
    "    df: dataframe\n",
    "    \"\"\"\n",
    "    df[category_col] = np.where(\n",
    "        df[search_col].str.contains('|'.join(search_terms)), 1, df[category_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QE4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Cleaning\n",
    "- Drop empty rows\n",
    "- Convert to lower case\n",
    "- Remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:30.807128Z",
     "start_time": "2021-03-16T17:47:30.635591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty rows: 101574\n",
      "Number of remaining rows: 787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-2865e23fd6e3>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  E4b[\"QE4b\"] = E4b[\"QE4b\"].str.replace(\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe that only includes the column of interest\n",
    "E4b = mop_2020[[\"QE4b\"]]\n",
    "' '\n",
    "# Check for empty columns:\n",
    "num_empty = len(E4b[(E4b[\"QE4b\"] == \"\") | (\n",
    "    E4b[\"QE4b\"] == \" \") | (E4b[\"QE4b\"].isna())].index)\n",
    "print(f\"Number of empty rows: {num_empty}\")\n",
    "\n",
    "# Drop empty columms\n",
    "E4b = E4b[(E4b[\"QE4b\"] != \"\") & (\n",
    "    E4b[\"QE4b\"] != \" \") & (E4b[\"QE4b\"].notna())]\n",
    "\n",
    "print(f\"Number of remaining rows: {len(E4b['QE4b'].index)}\")\n",
    "\n",
    "E4b[\"QE4b\"] = E4b[\"QE4b\"].str.replace(\n",
    "    \"[^\\w\\s]\", \"\").str.lower()\n",
    "\n",
    "# Lemmatize\n",
    "# Create a list to save the corrected spellings\n",
    "E4b_sentence_list = []\n",
    "\n",
    "# Iterate through each sentence in E4b_sentence_list\n",
    "for sentence in E4b[\"QE4b\"].tolist():\n",
    "\n",
    "    # List to store lemmatized words\n",
    "    sentence_lemmatized = []\n",
    "\n",
    "    # Iterate through each word in sentence\n",
    "    for word in sentence.split():\n",
    "\n",
    "        if word == \"less\":\n",
    "\n",
    "            # Append \"less\" to sentence_lemmatized\n",
    "            sentence_lemmatized.append(word)\n",
    "\n",
    "        # Append the lemmatized word to sentence_lemmatized\n",
    "        else:\n",
    "            sentence_lemmatized.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # Append the lemmatized sentence (converted back into one string) to E4b_sentence_list_lemmatized\n",
    "    E4b_sentence_list.append(\" \".join(sentence_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, mispelled words are manually corrected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:35.223745Z",
     "start_time": "2021-03-16T17:47:35.219778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create one string \"i dont like..\" from a list of strings [\"i dont like...\",\"this is...\",\"\"]\n",
    "E4b_one_string =\" \".join(E4b_sentence_list)\n",
    "# Create a list of words [\"i\", \"dont\", \"like\"...] from one string \"i dont like..\"\n",
    "E4b_word_list = E4b_one_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:37.026194Z",
     "start_time": "2021-03-16T17:47:36.858680Z"
    },
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "# Init the SpellChecker\n",
    "spell = SpellChecker(language=\"en\") \n",
    "\n",
    "# Generate a list of potentially misspelled words\n",
    "E4b_word_list_misspelled = spell.unknown(E4b_word_list)\n",
    "\n",
    "# Sort question_E4b_en_word_list_misspelled alphabetically (a-z)\n",
    "E4b_word_list_misspelled = sorted(E4b_word_list_misspelled)\n",
    "\n",
    "# The output below was used to generate the detect the mispellings\n",
    "# the SpellChecker library's 'most likely'\n",
    "# for word in E4b_word_list_misspelled:\n",
    "#     print(f\"word: {word} | most likely: {spell.correction(word)}\")\n",
    "\n",
    "# # Create a list to save the corrected spellings\n",
    "# E4b_sentence_list = []\n",
    "\n",
    "for i in range(len(E4b_sentence_list)):\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"aceepted\", \"accepted\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"almoat \", \"almost\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"aslo\", \"also\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"atm's\", \"atms\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"atmsbanks\", \"atms banks\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"avlid \", \"avoid\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"bancrupupt \", \"bankrupt\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"bettertap\", \"better tap\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"bettertap\", \"better tap\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"cardtap\", \"card tap\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"cashand\", \"cash and\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"cashcoins\", \"cash coins\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\n",
    "        \"cashlessdistancing\", \"cashless distancing\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"chrismas\", \"christmas\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\n",
    "        \"concernseasyconvenient\", \"concerns easy convenient\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"contactlesstap\", \"contactless tap\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"coronvairus\", \"coronavirus\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"covid019\", \"covid\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"covid19\", \"covid\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"covidf\", \"covid\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"creditdebit\", \"credit debit\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"creditdebittap\", \"credit debit tap\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"currencyi\", \"currency\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"debitcredit\", \"credit debit\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"debitmastercard\", \"debit mastercard\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"debtsi\", \"debit\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"essentiels\", \"essentials\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"evenchoice\", \"even choice\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"foodrestaurants\", \"food restaurants\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"factorlike\", \"factor like\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"inconvinent\", \"inconvenient\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"limitthis\", \"limit this\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"makong\", \"making\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"nocash\", \"no cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"oftensome\", \"often some\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"onlinepreordering\", \"online preordering\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"onormally\", \"normally\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"onlone\", \"online\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"pandamic\", \"pandemic\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"pandemy\", \"pandemic\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"payandgo\", \"pay and go\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"paymentspurchase\", \"payment purchase\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"phonefind\", \"phone find\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"phoneto\", \"phone to\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"pndemic\", \"pandemic\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"retaliers\", \"retailers\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"returnsbetter\", \"returns better\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"secureand\", \"secure and\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"selectionat\", \"selection at\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"selfcheckouts\", \"self checkouts\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"servicedelivery\", \"service delivery\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"shoppay\", \"shopping\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"shoppingpayments\", \"shopping payments\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"smallfrequent\", \"small frequent\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"transactionsat\", \"transactions at\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"transactions\", \"more\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"thisthere\", \"this there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, commonly occuring French phrases and words are translated to English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:43.647241Z",
     "start_time": "2021-03-16T17:47:38.979720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of French responses detected: 116\n"
     ]
    }
   ],
   "source": [
    "# lists to store responses by language\n",
    "E4b_sentence_list_fr = []\n",
    "\n",
    "# iterate through each sentence in E4b_sentence_list\n",
    "for sentence in E4b_sentence_list:\n",
    "    # detect the language using package langdetect\n",
    "    if detect(sentence) == \"fr\":\n",
    "        E4b_sentence_list_fr.append(sentence)\n",
    "\n",
    "print(f\"Number of French responses detected: {len(E4b_sentence_list_fr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:43.776827Z",
     "start_time": "2021-03-16T17:47:43.752894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 frequently occurring French words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('de', 155),\n",
       " ('plus', 52),\n",
       " ('le', 52),\n",
       " ('carte', 52),\n",
       " ('la', 49),\n",
       " ('en', 42),\n",
       " ('je', 39),\n",
       " ('comptant', 37),\n",
       " ('et', 36),\n",
       " ('contact', 35)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 frequently occurring French 2grams:\n",
      "Discerns: No lemmatizing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('carte', 'de'), 29),\n",
       " (('de', 'la'), 27),\n",
       " (('sans', 'contact'), 27),\n",
       " (('de', 'crédit'), 22),\n",
       " (('en', 'ligne'), 18),\n",
       " (('cause', 'de'), 18),\n",
       " (('largent', 'comptant'), 18),\n",
       " (('ma', 'carte'), 17),\n",
       " (('la', 'covid'), 17),\n",
       " (('à', 'cause'), 15)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 frequently occurring French 3grams:\n",
      "Discerns: No lemmatizing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('carte', 'de', 'crédit'), 22),\n",
       " (('cause', 'de', 'la'), 16),\n",
       " (('de', 'la', 'covid'), 15),\n",
       " (('ma', 'carte', 'de'), 13),\n",
       " (('à', 'cause', 'de'), 12),\n",
       " (('de', 'largent', 'comptant'), 6),\n",
       " (('carte', 'de', 'débit'), 6),\n",
       " (('la', 'carte', 'de'), 6),\n",
       " (('plus', 'dachat', 'en'), 5),\n",
       " (('dachat', 'en', 'ligne'), 5)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create one string \"i dont like..\" from a list of strings [\"i dont like...\",\"this is...\",\"\"]\n",
    "E4b_one_string_fr =\" \".join(E4b_sentence_list_fr)\n",
    "\n",
    "# Create a list of words [\"i\", \"dont\", \"like\"...] from one string \"i dont like..\"\n",
    "E4b_word_list_fr = E4b_one_string_fr.split()\n",
    "\n",
    "print(\"Top 10 frequently occurring French words:\")\n",
    "display(Counter(E4b_word_list_fr).most_common(10))\n",
    "\n",
    "print(\"Top 10 frequently occurring French 2grams:\")\n",
    "ngrams_discerns_fr = get_ngrams_discern(E4b_sentence_list_fr, 2)\n",
    "print(\"Discerns: No lemmatizing\")\n",
    "display(ngrams_discerns_fr.most_common(10))\n",
    "\n",
    "print(\"Top 10 frequently occurring French 3grams:\")\n",
    "ngrams_discerns_fr = get_ngrams_discern(E4b_sentence_list_fr, 3)\n",
    "print(\"Discerns: No lemmatizing\")\n",
    "display(ngrams_discerns_fr.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:51.361852Z",
     "start_time": "2021-03-16T17:47:51.348886Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(len(E4b_sentence_list)):\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"plus dachat ligne\",\"more online shopping\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"paiement sans contact\",\"contactless payment\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"sans contact carte\",\"contactless card\")\n",
    "#     E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"contact carte crédit\",\"\") Unsure about this one\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"plus dachats ligne\",\"more online shopping\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"carte sans contact\",\"contactless card\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"sans contact\",\"contactless\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"carte crédit\",\"credit card\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"largent comptant\",\"cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"carte débit\",\"debit card\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"argent comptant\",\"cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"dargent comptant\",\"cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"dargent comptant\",\"cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"plus\", \"more\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"carte\", \"card\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"contact\", \"contact\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"comptant\", \"cash\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"sans\", \"without\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"crédit\", \"credit\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"moins\", \"less\")\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"largent\", \"money\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, words are mapped so that synonyms are grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:53.497643Z",
     "start_time": "2021-03-16T17:47:53.491659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of 'pandemic' that will be mapped to covid: 64\n"
     ]
    }
   ],
   "source": [
    "# Create one string \"i dont like..\" from a list of strings [\"i dont like...\",\"this is...\",\"\"]\n",
    "E4b_one_string =\" \".join(E4b_sentence_list)\n",
    "\n",
    "# Create a list of words [\"i\", \"dont\", \"like\"...] from one string \"i dont like..\"\n",
    "E4b_word_list = E4b_one_string.split()\n",
    "\n",
    "print(f\"Instance of 'pandemic' that will be mapped to covid: {Counter(E4b_word_list)['pandemic']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:47:55.719132Z",
     "start_time": "2021-03-16T17:47:55.715143Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(E4b_sentence_list)):\n",
    "    # Add in additional mappings here as needed\n",
    "    E4b_sentence_list[i] = E4b_sentence_list[i].replace(\"pandemic\",\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a version of `E4b_sentence_list` that does not contain stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:52:27.644775Z",
     "start_time": "2021-03-16T17:52:27.582910Z"
    }
   },
   "outputs": [],
   "source": [
    "E4b_sentence_list_nostopwords = []\n",
    "\n",
    "for sentence in E4b_sentence_list:\n",
    "    sentence_no_stopwords = \" \".join([word for word in sentence.split() if word not in (stop_words)])\n",
    "    E4b_sentence_list_nostopwords.append(sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:52:29.666458Z",
     "start_time": "2021-03-16T17:52:29.626565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 frequently occurring words:\n",
      "-------------  ---\n",
      "('covid',)     340\n",
      "('cash',)      338\n",
      "('use',)       184\n",
      "('less',)      180\n",
      "('online',)    174\n",
      "('card',)      171\n",
      "('credit',)    130\n",
      "('using',)      96\n",
      "('shopping',)   94\n",
      "('tap',)        94\n",
      "-------------  ---\n",
      "Top 10 frequently occurring bigrams (discerns):\n",
      "----------------------  --\n",
      "('less', 'cash')        99\n",
      "('due', 'covid')        77\n",
      "('credit', 'card')      71\n",
      "('use', 'cash')         54\n",
      "('online', 'shopping')  54\n",
      "('debit', 'card')       43\n",
      "('tap', 'go')           41\n",
      "('use', 'less')         32\n",
      "('use', 'tap')          27\n",
      "('covid', '19')         26\n",
      "----------------------  --\n",
      "Top 10 frequently occurring trigrams (discerns):\n",
      "---------------------------  --\n",
      "('use', 'less', 'cash')      30\n",
      "('use', 'tap', 'go')         14\n",
      "('use', 'credit', 'card')    14\n",
      "('cash', 'due', 'covid')     14\n",
      "('using', 'less', 'cash')    12\n",
      "('less', 'cash', 'due')      10\n",
      "('using', 'credit', 'card')  10\n",
      "('using', 'debit', 'card')    8\n",
      "('use', 'debit', 'card')      8\n",
      "('due', 'covid', '19')        8\n",
      "---------------------------  --\n"
     ]
    }
   ],
   "source": [
    "ngrams_discerns = get_ngrams_discern(E4b_sentence_list_nostopwords, 1)\n",
    "print(\"Top 10 frequently occurring words:\")\n",
    "tabulate_counter(ngrams_discerns,10)\n",
    "\n",
    "print(\"Top 10 frequently occurring bigrams (discerns):\")\n",
    "ngrams_discerns = get_ngrams_discern(E4b_sentence_list_nostopwords, 2)\n",
    "tabulate_counter(ngrams_discerns,10)\n",
    "\n",
    "ngrams_discerns = get_ngrams_discern(E4b_sentence_list_nostopwords, 3)\n",
    "print(\"Top 10 frequently occurring trigrams (discerns):\")\n",
    "tabulate_counter(ngrams_discerns,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Word Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:18.639130Z",
     "start_time": "2021-03-16T18:52:18.632148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E4b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some indication that covid 19 can live on bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive been using my debit card more a because of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have more cash in hand thats why i pay more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more contactless and online payment purchase b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 E4b\n",
       "0  some indication that covid 19 can live on bank...\n",
       "1                                              covid\n",
       "2  ive been using my debit card more a because of...\n",
       "3  i have more cash in hand thats why i pay more ...\n",
       "4  more contactless and online payment purchase b..."
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the cleaned responses\n",
    "E4b_cleaned = pd.DataFrame(E4b_sentence_list,columns=[\"E4b\"])\n",
    "E4b_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:20.093668Z",
     "start_time": "2021-03-16T18:52:20.089695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column categories\n",
    "E4b_categorized = E4b_cleaned.reindex(\n",
    "    columns=E4b_cleaned.columns.tolist() + [\"less_cash\",\n",
    "                                            \"covid\",\n",
    "                                            \"credit_card\",\n",
    "                                            \"debit_card\", \n",
    "                                            \"business\",\n",
    "                                           \"online\"])\n",
    "\n",
    "# Define total number of responses\n",
    "total_responses_E4b = E4b_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"less cash\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:21.753250Z",
     "start_time": "2021-03-16T18:52:21.744301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 95\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "i carry less cash pay with touch and go i look online more than in store to avoid crowd\n",
      "\n",
      "covid _ use less cash\n",
      "\n",
      "use less cash since most retailer and cashier prefer not to handle cash these day\n",
      "\n",
      "i use less cash and more contactless because of covid\n",
      "\n",
      "i use less cash mostly because merchant request this a their preferred method of payment i typically would use more cash for smaller purchase\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"less cash\"]\n",
    "\n",
    "# Set column \"less_cash\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"less_cash\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"less_cash\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "# Print the number of rows that were categorized\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"covid\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:23.888718Z",
     "start_time": "2021-03-16T18:52:23.880775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 341\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "some indication that covid 19 can live on bank note greater likelihood of making contact with other people during the transaction\n",
      "\n",
      "covid\n",
      "\n",
      "ive been using my debit card more a because of covid lot of place werent accepting cash i on the other hand my only issue is leaving my self broke penny less more than often or more than what should be allowed but thats because i wa never taught the importance of money and saving so im a 21 year old that doesnt exactly care about money\n",
      "\n",
      "i have more cash in hand thats why i pay more with cash not covid related covid ha no influence in my decision how to pay\n",
      "\n",
      "more contactless and online payment purchase because of covid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"covid\"]\n",
    "\n",
    "# Set column \"covid\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"covid\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"covid\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "# Print the number of rows that were categorized\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"debit card\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:26.584806Z",
     "start_time": "2021-03-16T18:52:26.576851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 92\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "ive been using my debit card more a because of covid lot of place werent accepting cash i on the other hand my only issue is leaving my self broke penny less more than often or more than what should be allowed but thats because i wa never taught the importance of money and saving so im a 21 year old that doesnt exactly care about money\n",
      "\n",
      "some business are preferring not to use cash if possible so i would use debit more than credit card if banking fee were eliminated\n",
      "\n",
      "no concern just the fact the debit payment is so easy\n",
      "\n",
      "use credit debit more because of vendor request\n",
      "\n",
      "less cash more debit to quicken the transaction in light of covid and lessen the risk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"debit\"]\n",
    "\n",
    "# Set column \"debit_card\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"debit_card\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"debit_card\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "# Print the number of rows that were categorized\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"credit\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:28.744576Z",
     "start_time": "2021-03-16T18:52:28.736633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 133\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "i used credit card for everything so it is tracked and i have time to review charge and pay or dispute injustice charge\n",
      "\n",
      "some business are preferring not to use cash if possible so i would use debit more than credit card if banking fee were eliminated\n",
      "\n",
      "use credit debit more because of vendor request\n",
      "\n",
      "most store were asking for you to use credit or debit card\n",
      "\n",
      "i use credit card more frequently at grocery store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"credit\"]\n",
    "\n",
    "# Set column \"credit_card\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"credit_card\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"credit_card\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "# Print the number of rows that were categorized\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"business\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:31.480096Z",
     "start_time": "2021-03-16T18:52:31.472117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 23\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "some business are preferring not to use cash if possible so i would use debit more than credit card if banking fee were eliminated\n",
      "\n",
      "using debit card more and cash less a a lot of business prefer that during the covid\n",
      "\n",
      "less cash due to covid a business are less likely to accept it more online purchasing than before but overall less purchasing in general\n",
      "\n",
      "tap and go is faster and safer than punching in a code at a machine also i prefer cash but if a business prefers tap then i will oblige i use on line for curb side pick up only never for delivery in my area of town one doe not want delivery of parcel\n",
      "\n",
      "less cash and more credit still some business like canada post dont take cash any more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"business\"]\n",
    "\n",
    "# Set column \"business\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"business\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"business\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "# Print the number of rows that were categorized\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**online**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:50.945079Z",
     "start_time": "2021-03-16T18:52:50.936104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows >1 search_terms: 175\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "more contactless and online payment purchase because of covid\n",
      "\n",
      "due to the covid i made 95 of my purchase online\n",
      "\n",
      "feel more secure with safeguard for making online purchase\n",
      "\n",
      "i carry less cash pay with touch and go i look online more than in store to avoid crowd\n",
      "\n",
      "covid ha made me do more online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the key terms\n",
    "search_terms = [\"online\"]\n",
    "\n",
    "# Set column \"online\" equal to 1 for \"QE3\" containing any words in search_terms\n",
    "categorize(search_terms, \"E4b\", \"online\", E4b_categorized)\n",
    "\n",
    "num_categorized = E4b_categorized[E4b_categorized[\"online\"]==1].shape[0]\n",
    "print(f\"Number of rows >1 search_terms: {num_categorized}\\n\")\n",
    "\n",
    "print(f\"Total number of responses: {total_responses_E4b}\\n\")\n",
    "\n",
    "print(\"Examples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", E4b_cleaned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"less cash\" and \"covid\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:50:26.588844Z",
     "start_time": "2021-03-16T19:50:26.580868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses including both 'less cash' and 'covid': 48\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "covid _ use less cash\n",
      "\n",
      "i use less cash and more contactless because of covid\n",
      "\n",
      "less cash more debit to quicken the transaction in light of covid and lessen the risk\n",
      "\n",
      "less cash because of the covid\n",
      "\n",
      "less cash due to covid a business are less likely to accept it more online purchasing than before but overall less purchasing in general\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms=[\"less cash\",\"covid\"]\n",
    "less_cash_covid = E4b_categorized[(E4b_categorized[\"less_cash\"]==1)&(E4b_categorized[\"covid\"]==1)]\n",
    "print(f\"Number of responses including both 'less cash' and 'covid': {less_cash_covid.shape[0]}\")\n",
    "print(f\"\\nTotal number of responses: {total_responses_E4b}\")\n",
    "print(\"\\nExamples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", less_cash_covid, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"covid\" and \"business\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:51:59.043098Z",
     "start_time": "2021-03-16T19:51:59.035118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses including both 'covid' and 'business': 10\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "using debit card more and cash less a a lot of business prefer that during the covid\n",
      "\n",
      "less cash due to covid a business are less likely to accept it more online purchasing than before but overall less purchasing in general\n",
      "\n",
      "more online shopping due to the covid concern about small business\n",
      "\n",
      "i am using less cash because a good number of business are not accepting cash due to covid 19\n",
      "\n",
      "a ive explained there were many business that stopped accepting cash during covid bank increased the maximum for tap and go purchase and atm were either out of order not filled up with cash very often or simply were too expensive with the sur charge to use therefore i have used my debit card much more and cash much less i no longer have loose change lying around in my wallet to buy a pop from a machine at work for example also by using bank card it is easier to track spending and make appropriate change since covid ha put a strain on finance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms=[\"covid\",\"business\"]\n",
    "covid_business = E4b_categorized[(E4b_categorized[\"covid\"]==1)&(E4b_categorized[\"business\"]==1)]\n",
    "print(f\"Number of responses including both 'covid' and 'business': {covid_business.shape[0]}\")\n",
    "print(f\"\\nTotal number of responses: {total_responses_E4b}\")\n",
    "print(\"\\nExamples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", covid_business, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"less cash\" and \"business\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:51:02.706217Z",
     "start_time": "2021-03-16T19:51:02.700232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses including both 'less cash' and 'business': 6\n",
      "\n",
      "Total number of responses: 787\n",
      "\n",
      "Examples:\n",
      "\n",
      "less cash due to covid a business are less likely to accept it more online purchasing than before but overall less purchasing in general\n",
      "\n",
      "less cash and more credit still some business like canada post dont take cash any more\n",
      "\n",
      "less cash a business asked not to use cash during the corona virus\n",
      "\n",
      "i am using less cash because a good number of business are not accepting cash due to covid 19\n",
      "\n",
      "well a lot of business either tell u from the beginning that cash isnt accepted host at a restaurant before they take u to the table sign posted at a food truck establishment etc so thats why we have been using less cash\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms=[\"less cash\",\"business\"]\n",
    "less_cash_business = E4b_categorized[(E4b_categorized[\"less_cash\"]==1)&(E4b_categorized[\"business\"]==1)]\n",
    "print(f\"Number of responses including both 'less cash' and 'business': {less_cash_business.shape[0]}\")\n",
    "print(f\"\\nTotal number of responses: {total_responses_E4b}\")\n",
    "print(\"\\nExamples:\\n\")\n",
    "print_query_results(search_terms, \"E4b\", less_cash_business, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Delimiting? - Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:58:17.943376Z",
     "start_time": "2021-03-16T19:58:17.925425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'online': 175\n",
      "Number of responses containing 'online' AND one or more delimiter: 68\n",
      "Number (of the 68) containing 'covid': 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E4b_split</th>\n",
       "      <th>because/dueto/since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more contactless and online payment purchase</td>\n",
       "      <td>of covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>the covid i made 95 of my purchase online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ordering online slightly more to avoid crowded...</td>\n",
       "      <td>the covid covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>of covid ive been buying a lot more stuff onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>less cash</td>\n",
       "      <td>covid a business are less likely to accept it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            E4b_split  \\\n",
       "4       more contactless and online payment purchase    \n",
       "7                                                       \n",
       "36  ordering online slightly more to avoid crowded...   \n",
       "49                                                      \n",
       "93                                         less cash    \n",
       "\n",
       "                                  because/dueto/since  \n",
       "4                                            of covid  \n",
       "7           the covid i made 95 of my purchase online  \n",
       "36                                    the covid covid  \n",
       "49   of covid ive been buying a lot more stuff onl...  \n",
       "93   covid a business are less likely to accept it...  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters = \"because|due to|since\"\n",
    "\n",
    "online = E4b_categorized[E4b_categorized[\"online\"] == 1][[\"E4b\"]]\n",
    "online[[\"E4b_split\", \"because/dueto/since\"]\n",
    "       ] = online[\"E4b\"].str.split(delimiters, 1, expand=True)\n",
    "\n",
    "online_delim = online[(online[\"E4b_split\"].notna()) & (\n",
    "    online[\"because/dueto/since\"].notna())][[\"E4b_split\", \"because/dueto/since\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'online': {online.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'online' AND one or more delimiter: {online_delim.shape[0]}\")\n",
    "num_covid = query_num(\"covid\", \"because/dueto/since\", online_delim)\n",
    "print(f\"Number (of the {online_delim.shape[0]}) containing 'covid': {num_covid}\")\n",
    "\n",
    "online_delim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the responses without a delimiter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:58:20.226867Z",
     "start_time": "2021-03-16T19:58:20.220884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'online': 175\n",
      "Number of responses containing 'online' AND NO delimiter: 107\n",
      "Number (of the 107) containing 'covid': 107\n"
     ]
    }
   ],
   "source": [
    "online_no_delim = online[(online[\"E4b_split\"].isna()) | (\n",
    "    online[\"because/dueto/since\"].isna())][[\"E4b\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'online': {online.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'online' AND NO delimiter: {online_no_delim.shape[0]}\")\n",
    "num_covid = query_num(\"covid\", \"E4b\", online_no_delim)\n",
    "print(f\"Number (of the {online_no_delim.shape[0]}) containing 'covid': {num_covid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:45:34.822831Z",
     "start_time": "2021-03-16T19:45:34.817843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "\n",
      "feel more secure with safeguard for making online purchase\n",
      "\n",
      "i carry less cash pay with touch and go i look online more than in store to avoid crowd\n",
      "\n",
      "covid ha made me do more online\n",
      "\n",
      "covid 19 it all online ive been using paypal a lot more too it feel more secure\n",
      "\n",
      "access to store and the need to not have to travel combined with the ease of shopping online often at lower cost than shopping at a store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples:\\n\")\n",
    "print_query_results([\" \"], \"E4b\", online_no_delim, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "- Any mention of 'online' also includes 'covid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Delimiting? - Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:58:24.637677Z",
     "start_time": "2021-03-16T19:58:24.620721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'card': 179\n",
      "Number of responses containing 'card' AND one or more delimiter: 58\n",
      "Number (of the 58) containing 'covid': 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E4b_split</th>\n",
       "      <th>because/dueto/since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive been using my debit card more a</td>\n",
       "      <td>of covid lot of place werent accepting cash i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>use credit debit more</td>\n",
       "      <td>of vendor request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>place are preferring not to handle cash i dont...</td>\n",
       "      <td>of this there being no special allowance due ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td></td>\n",
       "      <td>covid using credit debit card more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>i use my debit card much more than cash just</td>\n",
       "      <td>of the covid caution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             E4b_split  \\\n",
       "2                 ive been using my debit card more a    \n",
       "31                              use credit debit more    \n",
       "47   place are preferring not to handle cash i dont...   \n",
       "99                                                       \n",
       "100      i use my debit card much more than cash just    \n",
       "\n",
       "                                   because/dueto/since  \n",
       "2     of covid lot of place werent accepting cash i...  \n",
       "31                                   of vendor request  \n",
       "47    of this there being no special allowance due ...  \n",
       "99                  covid using credit debit card more  \n",
       "100                               of the covid caution  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters = \"because|due to|since\"\n",
    "\n",
    "card = E4b_categorized[(E4b_categorized[\"credit_card\"] == 1)|(E4b_categorized[\"debit_card\"] == 1)][[\"E4b\"]]\n",
    "card[[\"E4b_split\", \"because/dueto/since\"]\n",
    "       ] = card[\"E4b\"].str.split(delimiters, 1, expand=True)\n",
    "card_delim = card[(card[\"E4b_split\"].notna()) & (\n",
    "    card[\"because/dueto/since\"].notna())][[\"E4b_split\", \"because/dueto/since\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'card': {card.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'card' AND one or more delimiter: {card_delim.shape[0]}\")\n",
    "num_covid = query_num(\"covid\", \"because/dueto/since\", card_delim)\n",
    "print(f\"Number (of the {card_delim.shape[0]}) containing 'covid': {num_covid}\")\n",
    "\n",
    "card_delim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the responses that do not contain a delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:58:27.804340Z",
     "start_time": "2021-03-16T19:58:27.796361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'card': 179\n",
      "Number of responses containing 'card' AND NO delimiter: 121\n",
      "Number (of the 121) containing 'covid': 121\n",
      "\n",
      "Examples:\n",
      "\n",
      "i used credit card for everything so it is tracked and i have time to review charge and pay or dispute injustice charge\n",
      "\n",
      "some business are preferring not to use cash if possible so i would use debit more than credit card if banking fee were eliminated\n",
      "\n",
      "no concern just the fact the debit payment is so easy\n",
      "\n",
      "less cash more debit to quicken the transaction in light of covid and lessen the risk\n",
      "\n",
      "most store were asking for you to use credit or debit card\n",
      "\n"
     ]
    }
   ],
   "source": [
    "card_no_delim = card[(card[\"E4b_split\"].isna()) | (\n",
    "    card[\"because/dueto/since\"].isna())][[\"E4b\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'card': {card.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'card' AND NO delimiter: {card_no_delim.shape[0]}\")\n",
    "num_covid = query_num(\"covid\", \"E4b\", card_no_delim)\n",
    "print(f\"Number (of the {card_no_delim.shape[0]}) containing 'covid': {num_covid}\")\n",
    "\n",
    "print(\"\\nExamples:\\n\")\n",
    "print_query_results([\" \"], \"E4b\", card_no_delim, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Delimiting? - Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:58:39.750815Z",
     "start_time": "2021-03-16T19:58:39.733862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'business': 23\n",
      "Number of responses containing 'business' AND one or more delimiter: 7\n",
      "Number (of the 7) containing 'covid': 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E4b_split</th>\n",
       "      <th>because/dueto/since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>less cash</td>\n",
       "      <td>covid a business are less likely to accept it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>more online shopping</td>\n",
       "      <td>the covid concern about small business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>i am using less cash</td>\n",
       "      <td>a good number of business are not accepting c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>i tend to use debit card more if i dont have e...</td>\n",
       "      <td>virus concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>a ive explained there were many business that ...</td>\n",
       "      <td>covid ha put a strain on finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             E4b_split  \\\n",
       "93                                          less cash    \n",
       "158                              more online shopping    \n",
       "186                              i am using less cash    \n",
       "227  i tend to use debit card more if i dont have e...   \n",
       "294  a ive explained there were many business that ...   \n",
       "\n",
       "                                   because/dueto/since  \n",
       "93    covid a business are less likely to accept it...  \n",
       "158             the covid concern about small business  \n",
       "186   a good number of business are not accepting c...  \n",
       "227                                      virus concern  \n",
       "294                   covid ha put a strain on finance  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters = \"because|due to|since\"\n",
    "\n",
    "business = E4b_categorized[E4b_categorized[\"business\"] == 1][[\"E4b\"]]\n",
    "business[[\"E4b_split\", \"because/dueto/since\"]\n",
    "       ] = business[\"E4b\"].str.split(delimiters, 1, expand=True)\n",
    "\n",
    "business_delim = business[(business[\"E4b_split\"].notna()) & (\n",
    "    business[\"because/dueto/since\"].notna())][[\"E4b_split\", \"because/dueto/since\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'business': {business.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'business' AND one or more delimiter: {business_delim.shape[0]}\")\n",
    "num_covid = query_num(\"covid\", \"because/dueto/since\", business_delim)\n",
    "print(f\"Number (of the {business_delim.shape[0]}) containing 'covid': {num_covid}\")\n",
    "\n",
    "business_delim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the responses that do not contain a delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:59:21.172972Z",
     "start_time": "2021-03-16T19:59:21.164992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses containing 'business': 23\n",
      "Number of responses containing 'business' AND NO delimiter: 16\n",
      "Number (of the 16) containing 'business': 16\n",
      "\n",
      "Examples:\n",
      "\n",
      "some business are preferring not to use cash if possible so i would use debit more than credit card if banking fee were eliminated\n",
      "\n",
      "using debit card more and cash less a a lot of business prefer that during the covid\n",
      "\n",
      "tap and go is faster and safer than punching in a code at a machine also i prefer cash but if a business prefers tap then i will oblige i use on line for curb side pick up only never for delivery in my area of town one doe not want delivery of parcel\n",
      "\n",
      "less cash and more credit still some business like canada post dont take cash any more\n",
      "\n",
      "less cash a business asked not to use cash during the corona virus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business_no_delim = business[(business[\"E4b_split\"].isna()) | (\n",
    "    business[\"because/dueto/since\"].isna())][[\"E4b\"]]\n",
    "\n",
    "print(f\"Number of responses containing 'business': {business.shape[0]}\")\n",
    "print(\n",
    "    f\"Number of responses containing 'business' AND NO delimiter: {business_no_delim.shape[0]}\")\n",
    "num_business = query_num(\"business\", \"E4b\", business_no_delim)\n",
    "print(f\"Number (of the {business_no_delim.shape[0]}) containing 'business': {num_business}\")\n",
    "\n",
    "print(\"\\nExamples:\\n\")\n",
    "print_query_results([\" \"], \"E4b\", business_no_delim, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "190.764px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
